# CLAUDE INSTRUCTIONS - LLM Training System

**Last Updated:** 2025-11-22 (Production Integration Complete)
**Update Frequency:** Every ~50k tokens or when significant changes occur

This document contains instructions for Claude to help with training operations.

**MAJOR UPDATE:** Refactored trainer/ modules now integrated into production (core/train.py)
- âœ… Steps 1-5: Created trainer/ architecture (config, profiles, monitoring)
- âœ… **NEW:** Production integration - core/train.py uses ConfigLoader + profiles

---

## ðŸ“‹ COMMUNICATION STYLE

**Default mode: Factual technical documentation**

- State facts about system behavior, configuration, and current state
- Do not include recommendations, suggestions, or opinions unless explicitly asked
- Do not add phrases like "I recommend", "you should", "it's best to", "consider"
- Present options without bias when multiple approaches exist
- Omit evaluative language ("excellent", "better", "perfect", "brilliant")
- When asked "how does X work", describe the mechanism without suggesting changes
- When asked "what are the options", list them without ranking

**Example:**
- âŒ "I recommend using batch_size=30 because it's more efficient"
- âœ… "batch_size=30 uses ~21GB VRAM. batch_size=16 uses ~14GB VRAM"

**Only add recommendations when:**
- Explicitly asked ("what should I do?", "which is better?")
- Critical safety issue (data loss, system damage)
- User makes factual error that needs correction

---

## ðŸš¨ CRITICAL RULES

### Documentation Policies

1. **7 Canonical Docs** - Only write to these 7 files:
   - `README.md` - System overview
   - `QUICKSTART.md` - Getting started guide
   - `ARCHITECTURE.md` - How the system works
   - `TROUBLESHOOTING.md` - Common problems and solutions
   - `REMOTE_INFERENCE.md` - **â­ Remote RTX 3090 inference server (primary reference)**
   - `DEVELOPMENT.md` - Working on the codebase
   - `CHANGELOG.md` - Track changes

2. **CLAUDE.md Updates** - Update this file every ~50k tokens or when significant changes occur

3. **No Other Docs** - Do NOT create any other .md files without explicit user permission

4. **Remote Inference Focus** - See `REMOTE_INFERENCE.md` for all inference/generation tasks. This training machine does NOT run inference.

### Safety Policies

1. **NEVER delete `models/current_model/` without explicit user permission**
2. **ALWAYS create backup before risky operations**
3. **NEVER modify `config.json` critical parameters without user approval:**
   - `max_length`
   - `model_name`
   - `base_model`
4. **ASK FIRST** before making system-wide changes

---

## ðŸ“ DIRECTORY STRUCTURE

**Reorganized 2025-11-22** - All files organized + new trainer/ module added

```
/path/to/training/
â”‚
â”œâ”€â”€ CLAUDE.md                    # This file (Claude instructions)
â”œâ”€â”€ config.json                  # Active configuration
â”‚
â”œâ”€â”€ trainer/                     # ðŸ†• NEW: Refactored training modules (3-layer architecture)
â”‚   â”œâ”€â”€ config/                  # Layer 2: Configuration system
â”‚   â”‚   â”œâ”€â”€ schema.py            # 8 dataclasses (Hyperparams, ProfileConfig, etc.)
â”‚   â”‚   â””â”€â”€ loader.py            # ConfigLoader (JSON + CLI merging)
â”‚   â”œâ”€â”€ profiles/                # Layer 3: Pluggable data profiles
â”‚   â”‚   â”œâ”€â”€ base.py              # DataProfile ABC interface
â”‚   â”‚   â”œâ”€â”€ emoji_think.py       # Emoji thinking/stop profile
â”‚   â”‚   â””â”€â”€ regime3.py           # Symbolic reasoning profile (NEW!)
â”‚   â”œâ”€â”€ monitoring/              # Layer 3: Monitoring callbacks
â”‚   â”‚   â”œâ”€â”€ status_writer.py     # TrainingStatusWriter
â”‚   â”‚   â””â”€â”€ callbacks.py         # LiveMonitorCallback
â”‚   â”œâ”€â”€ core/                    # Layer 1: Engine API
â”‚   â”‚   â””â”€â”€ engine.py            # TrainerEngine.run_job() (proof-of-concept)
â”‚   â””â”€â”€ cli_main.py              # CLI demonstration
â”‚
â”œâ”€â”€ README.md                    # System overview
â”œâ”€â”€ QUICKSTART.md                # Getting started
â”œâ”€â”€ ARCHITECTURE.md              # System design
â”œâ”€â”€ TROUBLESHOOTING.md           # Problem solving
â”œâ”€â”€ DEVELOPMENT.md               # Development guide
â”œâ”€â”€ CHANGELOG.md                 # Change tracking
â”‚
â”œâ”€â”€ core/                        # Core training system (11 files)
â”‚   â”œâ”€â”€ train.py                 # Main training script (HuggingFace Trainer) - STILL WORKS
â”‚   â”œâ”€â”€ train_v1_backup.py       # Backup before refactor
â”‚   â”œâ”€â”€ training_daemon.py       # File watcher + orchestrator
â”‚   â”œâ”€â”€ training_controller.py   # Control commands (pause/resume/stop)
â”‚   â”œâ”€â”€ training_queue.py        # Queue management
â”‚   â”œâ”€â”€ training_status.py       # Status writer (copied to trainer/monitoring/)
â”‚   â”œâ”€â”€ custom_collator.py       # Data collator
â”‚   â”œâ”€â”€ logit_penalty.py         # Penalty processors
â”‚   â”œâ”€â”€ validator.py             # Data validation
â”‚   â”œâ”€â”€ model_db.py              # Model database
â”‚   â””â”€â”€ time_estimator.py        # Time estimation
â”‚
â”œâ”€â”€ monitoring/                  # Monitoring + Web UI
â”‚   â”œâ”€â”€ servers/                 # API servers
â”‚   â”‚   â”œâ”€â”€ live_monitor.py      # Main monitor server
â”‚   â”‚   â”œâ”€â”€ memory_stats_api.py  # Memory stats API
â”‚   â”‚   â””â”€â”€ enhanced_monitor.py  # Enhanced monitoring
â”‚   â”œâ”€â”€ ui/                      # HTML files
â”‚   â”‚   â””â”€â”€ *.html
â”‚   â”œâ”€â”€ js/                      # JavaScript modules
â”‚   â””â”€â”€ css/                     # Stylesheets
â”‚
â”œâ”€â”€ management/                  # Model/backup management
â”‚   â”œâ”€â”€ backup_manager.py        # Backup system
â”‚   â”œâ”€â”€ model_versioner.py       # Version control
â”‚   â”œâ”€â”€ consolidate_model.py     # Model consolidation
â”‚   â”œâ”€â”€ checkpoint_retention.py  # Checkpoint cleanup
â”‚   â”œâ”€â”€ safe_checkpoint_cleanup.py
â”‚   â”œâ”€â”€ daily_snapshot.py        # Daily snapshots
â”‚   â””â”€â”€ auto_disk_manager.py     # Auto disk cleanup
â”‚
â”œâ”€â”€ safety/                      # Watchdogs + health checks
â”‚   â”œâ”€â”€ daemon_watchdog.py       # Auto-restart daemon
â”‚   â”œâ”€â”€ anti_stuck_monitor.py    # Detect hangs
â”‚   â”œâ”€â”€ crash_detector.py        # Crash analysis
â”‚   â”œâ”€â”€ comprehensive_health_check.py
â”‚   â”œâ”€â”€ config_validator.py      # Config validation
â”‚   â””â”€â”€ verify_checkpoint_resume.py
â”‚
â”œâ”€â”€ tools/                       # Utilities
â”‚   â”œâ”€â”€ data/                    # Data processing
â”‚   â”‚   â”œâ”€â”€ generate_syllo_batch.py
â”‚   â”‚   â”œâ”€â”€ validate_data.py
â”‚   â”‚   â”œâ”€â”€ convert_*.py
â”‚   â”‚   â””â”€â”€ analyze_training_data.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ edit_config.py
â”‚   â””â”€â”€ analysis/
â”‚       â”œâ”€â”€ state_tracker.py     # System state tracking
â”‚       â”œâ”€â”€ calculate_data_value.py
â”‚       â””â”€â”€ compare_models.py
â”‚
â”œâ”€â”€ tests/                       # Test files
â”‚   â””â”€â”€ test_*.py
â”‚
â”œâ”€â”€ scripts/                     # Shell scripts
â”‚   â”œâ”€â”€ start_all.sh             # Start all services
â”‚   â”œâ”€â”€ check_health.sh          # Health check
â”‚   â””â”€â”€ bin/                     # Launcher scripts
â”‚
â”œâ”€â”€ data/                        # Training data
â”‚   â”œâ”€â”€ validation/              # Fixed validation set
â”‚   â””â”€â”€ flagged_examples/        # Flagged outputs
â”‚
â”œâ”€â”€ models/                      # Model storage
â”‚   â”œâ”€â”€ Qwen3-0.6B/              # Base model (1.5GB)
â”‚   â”œâ”€â”€ current_model/           # Active checkpoint (EMPTY - needs setup)
â”‚   â””â”€â”€ current_model_small/     # Small model checkpoint
â”‚
â”œâ”€â”€ backups/                     # Backups
â”‚   â””â”€â”€ consolidated/            # Consolidated backups
â”‚
â”œâ”€â”€ logs/                        # Training logs (daily rotation)
â”œâ”€â”€ status/                      # Status JSON files
â”œâ”€â”€ control/                     # Control files (.stop, .pause, etc.)
â”œâ”€â”€ inbox/                       # Drop zone for training files
â”œâ”€â”€ queue/                       # Priority queues
â”‚   â”œâ”€â”€ high/
â”‚   â”œâ”€â”€ normal/
â”‚   â”œâ”€â”€ low/
â”‚   â”œâ”€â”€ processing/              # Currently training
â”‚   â”œâ”€â”€ failed/                  # Failed files
â”‚   â””â”€â”€ recently_completed/
â”‚
â”œâ”€â”€ scratch/                     # Working space for design docs & experiments
â”‚   â”œâ”€â”€ DAEMON_REFACTOR_PLAN.md  # Current work: daemon refactor planning
â”‚   â”œâ”€â”€ IMPLEMENTATION_PLAN_TASKS.md  # Task breakdowns
â”‚   â”œâ”€â”€ MONITORING_V2_DESIGN.md  # Monitoring system designs
â”‚   â”œâ”€â”€ RETENTION_POLICY_DESIGN.md   # Policy documents
â”‚   â””â”€â”€ *.md                     # Other design/planning docs
â”‚
â””â”€â”€ archive/                     # Archived code & completed work
    â”œâ”€â”€ refactor_2025_11_22/     # Nov 22 trainer/ refactor
    â”‚   â”œâ”€â”€ code/                # Backup train.py versions
    â”‚   â”œâ”€â”€ docs/                # Refactor documentation
    â”‚   â””â”€â”€ tests/               # Profile & engine tests
    â”œâ”€â”€ configs/                 # Old config files
    â”œâ”€â”€ experiments/             # Old experiments
    â””â”€â”€ PERMANENT_ERROR_TRAINING/

# IGNORED (user data/notes):
GOTCHA_BUSINESS_MODEL/
OBSERVATIONS/
```

---

## ðŸ†• RECENT UPDATES (2025-11-22)

**Production Integration Complete** - trainer/ modules now in core/train.py (commit: 5cdebe4)

**What's New:**
- ConfigLoader integrated - single TrainerConfig from args + config.json
- Profiles active - emoji_think & regime3 available via config
- Precision unified - model load + training use same precision (bf16/fp16/fp32)
- System prompt fixed - uses `--system-prompt` CLI arg
- 100% backward compatible - falls back to legacy if needed

**Quick Start:**
```bash
# Edit config.json to switch profiles
{"profile": {"name": "regime3"}}  # or "emoji_think"

# Run training (automatically uses profile + config)
python3 core/train.py --dataset data.jsonl --model qwen3 --output outputs
```

**Refactor Timeline:**
- Steps 1-5: Created trainer/ architecture (6 git tags)
- Step 6: Production integration (this update)
- Result: ~3,400 lines â†’ 14 modules, fully tested, in production

**Key Files:**
- `trainer/config/` - ConfigLoader, TrainerConfig schema
- `trainer/profiles/` - emoji_think, regime3 data profiles
- `core/train.py` - Production script (now uses trainer/ modules)

See CHANGELOG.md for details

---

## ðŸŽ¯ CURRENT SYSTEM STATE

**Last Verified:** 2025-11-22 04:40 AM

### Model Status
- **Base model:** Qwen3-0.6B (exists at `/path/to/training/models/Qwen3-0.6B/`)
  - Size: 1.5GB
  - Type: Qwen3ForCausalLM
  - Hidden size: 1024, Layers: 28, Vocab: 151936
- **Current model:** EMPTY (needs initialization)
- **Training method:** Full model fine-tuning (no LoRA)
- **Last training attempt:** Failed with OOM at 04:02 AM

### Queue Status
- **Normal queue:** 0 files
- **Stuck files:** 3 files (287MB each, 100k examples)
  - 2 in `queue/failed/`
  - 1 in `queue/processing/`
- **Issue:** OOM crashes during training

### Service Status
- âœ… Disk manager: Running
- âŒ Training daemon: NOT running (PID dead)
- âŒ Monitors: NOT running
- âŒ Watchdogs: NOT running

### Configuration (`config.json`)
```json
{
  "model_name": "qwen2.5_0.5b",
  "model_path": "/path/to/training/models/Qwen3-0.6B",
  "batch_size": 19,
  "learning_rate": 0.0002,
  "eval_steps": 50,
  "save_steps": 1000,
  "max_length": 4096,
  "poll_interval": 30
}
```

### Disk Space
- **Available:** 731GB / 1.8TB (58% used)
- **Status:** Healthy

---

## âš¡ QUICK OPERATIONS

### Start All Services
```bash
cd /path/to/training
scripts/start_all.sh
```

This starts:
1. Auto disk manager
2. Training daemon
3. Live monitor (port 8080)
4. Memory stats API (port 8081)
5. Enhanced monitor (port 8082)

### Control Training
```bash
# Check status
python3 core/training_controller.py status

# Pause/resume/stop
python3 core/training_controller.py pause
python3 core/training_controller.py resume
python3 core/training_controller.py stop
```

### Queue Management
```bash
# Add file to queue
python3 core/training_queue.py add mydata.jsonl --priority high

# Check queue status
python3 core/training_queue.py status
python3 core/training_queue.py list
```

### Health Check
```bash
scripts/check_health.sh
python3 safety/comprehensive_health_check.py
python3 tools/analysis/state_tracker.py --check
```

### Monitor URLs
- Main UI: http://localhost:8080/live_monitor_ui_v2.html
- Memory Stats: http://localhost:8081/api/memory_stats
- Status JSON: http://localhost:8080/status/training_status.json

---

## ðŸ”§ COMMON ISSUES

### Training Daemon Not Running
```bash
# Check if running
ps aux | grep training_daemon | grep -v grep

# Restart if needed
cd /path/to/training
nohup python3 core/training_daemon.py --base-dir /path/to/training > training_output.log 2>&1 &
```

### OOM (Out of Memory) Crashes
**Symptoms:** Training crashes with CUDA OOM error

**Common causes:**
1. Batch size too high for available VRAM
2. Multiple daemon processes running (check with `ps aux`)
3. Eval step inference not clearing cache
4. Model too large for GPU

**Actions:**
```bash
# Check for multiple processes
ps aux | grep "python3.*training_daemon" | grep -v grep

# Kill all if multiple found
pkill -f training_daemon
sleep 3

# Reduce batch size
python3 tools/config/edit_config.py batch_size 16

# Restart daemon
nohup python3 core/training_daemon.py --base-dir /path/to/training > training_output.log 2>&1 &
```

### Stuck Files in Queue
**Check:**
```bash
ls -lh queue/processing/
ls -lh queue/failed/
```

**Clear:**
```bash
# Move back to normal queue (ask user first!)
mv queue/processing/* queue/normal/
mv queue/failed/* queue/normal/
```

---

## ðŸ“Š VALIDATION & METRICS

### Check Training Status
```bash
cat status/training_status.json | jq '{
  step: .current_step,
  train_loss: .loss,
  val_loss: .validation_loss,
  gap: .val_train_gap
}'
```

### Interpret Metrics
- **Train/Val Gap:**
  - < 0.3: Generalizing well
  - 0.3 - 0.5: Monitor closely
  - > 0.5: Possible overfitting

### Validate Data
```bash
python3 tools/data/validate_data.py --file my_data.jsonl
```

---

## ðŸ“ NOTES FOR CLAUDE

### System History
- System reorganized 2025-11-22 (99 Python files â†’ organized into 6 categories)
- All old documentation deleted (16 .md files removed)
- Fresh start - trust code as ground truth, not old docs

### Current Priorities
1. Fix stuck queue files (3 x 287MB files causing OOM)
2. Restart training daemon
3. Monitor system health

### When in Doubt
1. Run health check: `python3 safety/comprehensive_health_check.py`
2. Check system state: `python3 tools/analysis/state_tracker.py --check`
3. **ASK USER** before making changes
4. **ASK USER** before creating new documentation

---

## ðŸ”„ UPDATE LOG

**2025-11-22 (Late - Refactor Complete):**
- âœ… Completed full 5-step refactor (~3 hours)
- âœ… Created trainer/ module with 3-layer architecture
- âœ… Extracted config system (8 dataclasses, type-safe)
- âœ… Extracted emoji_think profile (emoji patterns + stop signals)
- âœ… Created regime3 profile (symbolic reasoning) â­ NEW
- âœ… Extracted monitoring system (callbacks + status writer)
- âœ… Created TrainerEngine API (proof-of-concept)
- âœ… 13/13 tests passing, 100% backward compatible
- âœ… All pushed to GitHub with 6 git tags
- **Production ready:** Can use new modules today or continue with core/train.py

**2025-11-22 (Morning - Reorganization):**
- Reorganized entire codebase (99 Python files â†’ 6 categories)
- Created 7 canonical documentation files
- Removed all old documentation (96+ files)
- Updated CLAUDE.md to reflect new structure
- **Architecture decision:** Pure training module - all inference on remote RTX 3090
- Added REMOTE_INFERENCE.md for remote server operations
- System state: Fresh start, daemon not running, 3 files stuck in queue

---

## ðŸ¤– AUTONOMOUS SYSTEMS (NEW - 2025-11-23)

**10 Intelligent Systems Running 24/7**

### RTX 3090 Systems (7 monitoring & intelligence)

1. **Curriculum Optimizer** - `monitoring/curriculum_optimizer.py`
   - A/B tests curriculum strategies every 5 minutes
   - Auto-adjusts difficulty progression
   - Output: `status/curriculum_optimization.json`

2. **Adversarial Miner** - `monitoring/adversarial_miner.py`
   - Mines hard examples from model failures
   - Creates targeted training data
   - Output: `data/adversarial_examples/*.jsonl`

3. **Regression Monitor** - `monitoring/continuous_regression_monitor.py`
   - Detects bad checkpoints (>15% loss increase)
   - Runs every 5 minutes
   - Output: `status/regression_monitoring.json`

4. **Model Comparison Engine** - `monitoring/model_comparison_engine.py`
   - Ranks checkpoints by composite score
   - Runs every 10 minutes
   - Output: `status/model_comparisons.json`

5. **Confidence Calibrator** - `monitoring/confidence_calibrator.py`
   - Calibrates prediction confidence
   - 6 confidence bins
   - Output: `status/confidence_calibration.json`

6. **Self-Correction Loop** - `monitoring/self_correction_loop.py`
   - Validates data quality
   - Captures & analyzes errors
   - Generates correction examples
   - Output: `queue/corrections/*.jsonl`, `logs/error_patterns/*.json`

7. **Automated Testing Daemon** - `monitoring/automated_testing_daemon.py`
   - Runs fixed validation suite against checkpoints
   - Calculates accuracy by difficulty
   - Detects regressions
   - Output: `status/automated_testing.json`

### RTX 4090 Systems (2 automation)

8. **Data Generation Automation** - `monitoring/data_generation_automation.py`
   - Auto-generates when queue < 2 files
   - Uses curriculum-optimized difficulty
   - Never runs out of data

9. **Checkpoint Auto-Deployment** - `monitoring/checkpoint_auto_deployment.py`
   - Auto-deploys best checkpoint to 3090
   - Based on model comparison rankings
   - Runs every 10 minutes

### Verify All Systems

```bash
# Check 3090 systems (should show 7)
ssh 192.168.x.x "ps aux | grep python3 | grep monitoring | wc -l"

# Check 4090 systems (should show 2)
ps aux | grep python3 | grep monitoring | wc -l

# View system status
cat status/*.json | jq .

# Monitor logs
tail -f logs/curriculum_optimizer.log
tail -f logs/self_correction.log
tail -f logs/automated_testing.log
```

### System Outputs

All systems write to `status/*.json` files:
- `curriculum_optimization.json` - Best curriculum strategy
- `adversarial_mining.json` - Hard examples found
- `regression_monitoring.json` - Regression alerts
- `model_comparisons.json` - Checkpoint rankings
- `confidence_calibration.json` - Confidence bins
- `automated_testing.json` - Validation results
- `last_deployment.json` - Latest checkpoint deployed

