# CLAUDE INSTRUCTIONS - LLM Training System

**Last Updated:** 2025-11-22 (Post-Refactor - Steps 1-5 Complete)
**Update Frequency:** Every ~50k tokens or when significant changes occur

This document contains instructions for Claude to help with training operations.

**MAJOR UPDATE:** Training system refactored into clean 3-layer architecture (Steps 1-5 complete)

---

## ğŸ“‹ COMMUNICATION STYLE

**Default mode: Factual technical documentation**

- State facts about system behavior, configuration, and current state
- Do not include recommendations, suggestions, or opinions unless explicitly asked
- Do not add phrases like "I recommend", "you should", "it's best to", "consider"
- Present options without bias when multiple approaches exist
- Omit evaluative language ("excellent", "better", "perfect", "brilliant")
- When asked "how does X work", describe the mechanism without suggesting changes
- When asked "what are the options", list them without ranking

**Example:**
- âŒ "I recommend using batch_size=30 because it's more efficient"
- âœ… "batch_size=30 uses ~21GB VRAM. batch_size=16 uses ~14GB VRAM"

**Only add recommendations when:**
- Explicitly asked ("what should I do?", "which is better?")
- Critical safety issue (data loss, system damage)
- User makes factual error that needs correction

---

## ğŸš¨ CRITICAL RULES

### Documentation Policies

1. **7 Canonical Docs** - Only write to these 7 files:
   - `README.md` - System overview
   - `QUICKSTART.md` - Getting started guide
   - `ARCHITECTURE.md` - How the system works
   - `TROUBLESHOOTING.md` - Common problems and solutions
   - `REMOTE_INFERENCE.md` - **â­ Remote RTX 3090 inference server (primary reference)**
   - `DEVELOPMENT.md` - Working on the codebase
   - `CHANGELOG.md` - Track changes

2. **CLAUDE.md Updates** - Update this file every ~50k tokens or when significant changes occur

3. **No Other Docs** - Do NOT create any other .md files without explicit user permission

4. **Remote Inference Focus** - See `REMOTE_INFERENCE.md` for all inference/generation tasks. This training machine does NOT run inference.

### Safety Policies

1. **NEVER delete `models/current_model/` without explicit user permission**
2. **ALWAYS create backup before risky operations**
3. **NEVER modify `config.json` critical parameters without user approval:**
   - `max_length`
   - `model_name`
   - `base_model`
4. **ASK FIRST** before making system-wide changes

---

## ğŸ“ DIRECTORY STRUCTURE

**Reorganized 2025-11-22** - All files organized + new trainer/ module added

```
/path/to/training/
â”‚
â”œâ”€â”€ CLAUDE.md                    # This file (Claude instructions)
â”œâ”€â”€ config.json                  # Active configuration
â”‚
â”œâ”€â”€ trainer/                     # ğŸ†• NEW: Refactored training modules (3-layer architecture)
â”‚   â”œâ”€â”€ config/                  # Layer 2: Configuration system
â”‚   â”‚   â”œâ”€â”€ schema.py            # 8 dataclasses (Hyperparams, ProfileConfig, etc.)
â”‚   â”‚   â””â”€â”€ loader.py            # ConfigLoader (JSON + CLI merging)
â”‚   â”œâ”€â”€ profiles/                # Layer 3: Pluggable data profiles
â”‚   â”‚   â”œâ”€â”€ base.py              # DataProfile ABC interface
â”‚   â”‚   â”œâ”€â”€ emoji_think.py       # Emoji thinking/stop profile
â”‚   â”‚   â””â”€â”€ regime3.py           # Symbolic reasoning profile (NEW!)
â”‚   â”œâ”€â”€ monitoring/              # Layer 3: Monitoring callbacks
â”‚   â”‚   â”œâ”€â”€ status_writer.py     # TrainingStatusWriter
â”‚   â”‚   â””â”€â”€ callbacks.py         # LiveMonitorCallback
â”‚   â”œâ”€â”€ core/                    # Layer 1: Engine API
â”‚   â”‚   â””â”€â”€ engine.py            # TrainerEngine.run_job() (proof-of-concept)
â”‚   â””â”€â”€ cli_main.py              # CLI demonstration
â”‚
â”œâ”€â”€ README.md                    # System overview
â”œâ”€â”€ QUICKSTART.md                # Getting started
â”œâ”€â”€ ARCHITECTURE.md              # System design
â”œâ”€â”€ TROUBLESHOOTING.md           # Problem solving
â”œâ”€â”€ DEVELOPMENT.md               # Development guide
â”œâ”€â”€ CHANGELOG.md                 # Change tracking
â”‚
â”œâ”€â”€ core/                        # Core training system (11 files)
â”‚   â”œâ”€â”€ train.py                 # Main training script (HuggingFace Trainer) - STILL WORKS
â”‚   â”œâ”€â”€ train_v1_backup.py       # Backup before refactor
â”‚   â”œâ”€â”€ training_daemon.py       # File watcher + orchestrator
â”‚   â”œâ”€â”€ training_controller.py   # Control commands (pause/resume/stop)
â”‚   â”œâ”€â”€ training_queue.py        # Queue management
â”‚   â”œâ”€â”€ training_status.py       # Status writer (copied to trainer/monitoring/)
â”‚   â”œâ”€â”€ custom_collator.py       # Data collator
â”‚   â”œâ”€â”€ logit_penalty.py         # Penalty processors
â”‚   â”œâ”€â”€ validator.py             # Data validation
â”‚   â”œâ”€â”€ model_db.py              # Model database
â”‚   â””â”€â”€ time_estimator.py        # Time estimation
â”‚
â”œâ”€â”€ monitoring/                  # Monitoring + Web UI
â”‚   â”œâ”€â”€ servers/                 # API servers
â”‚   â”‚   â”œâ”€â”€ live_monitor.py      # Main monitor server
â”‚   â”‚   â”œâ”€â”€ memory_stats_api.py  # Memory stats API
â”‚   â”‚   â””â”€â”€ enhanced_monitor.py  # Enhanced monitoring
â”‚   â”œâ”€â”€ ui/                      # HTML files
â”‚   â”‚   â””â”€â”€ *.html
â”‚   â”œâ”€â”€ js/                      # JavaScript modules
â”‚   â””â”€â”€ css/                     # Stylesheets
â”‚
â”œâ”€â”€ management/                  # Model/backup management
â”‚   â”œâ”€â”€ backup_manager.py        # Backup system
â”‚   â”œâ”€â”€ model_versioner.py       # Version control
â”‚   â”œâ”€â”€ consolidate_model.py     # Model consolidation
â”‚   â”œâ”€â”€ checkpoint_retention.py  # Checkpoint cleanup
â”‚   â”œâ”€â”€ safe_checkpoint_cleanup.py
â”‚   â”œâ”€â”€ daily_snapshot.py        # Daily snapshots
â”‚   â””â”€â”€ auto_disk_manager.py     # Auto disk cleanup
â”‚
â”œâ”€â”€ safety/                      # Watchdogs + health checks
â”‚   â”œâ”€â”€ daemon_watchdog.py       # Auto-restart daemon
â”‚   â”œâ”€â”€ anti_stuck_monitor.py    # Detect hangs
â”‚   â”œâ”€â”€ crash_detector.py        # Crash analysis
â”‚   â”œâ”€â”€ comprehensive_health_check.py
â”‚   â”œâ”€â”€ config_validator.py      # Config validation
â”‚   â””â”€â”€ verify_checkpoint_resume.py
â”‚
â”œâ”€â”€ tools/                       # Utilities
â”‚   â”œâ”€â”€ data/                    # Data processing
â”‚   â”‚   â”œâ”€â”€ generate_syllo_batch.py
â”‚   â”‚   â”œâ”€â”€ validate_data.py
â”‚   â”‚   â”œâ”€â”€ convert_*.py
â”‚   â”‚   â””â”€â”€ analyze_training_data.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ edit_config.py
â”‚   â””â”€â”€ analysis/
â”‚       â”œâ”€â”€ state_tracker.py     # System state tracking
â”‚       â”œâ”€â”€ calculate_data_value.py
â”‚       â””â”€â”€ compare_models.py
â”‚
â”œâ”€â”€ tests/                       # Test files
â”‚   â””â”€â”€ test_*.py
â”‚
â”œâ”€â”€ scripts/                     # Shell scripts
â”‚   â”œâ”€â”€ start_all.sh             # Start all services
â”‚   â”œâ”€â”€ check_health.sh          # Health check
â”‚   â””â”€â”€ bin/                     # Launcher scripts
â”‚
â”œâ”€â”€ data/                        # Training data
â”‚   â”œâ”€â”€ validation/              # Fixed validation set
â”‚   â””â”€â”€ flagged_examples/        # Flagged outputs
â”‚
â”œâ”€â”€ models/                      # Model storage
â”‚   â”œâ”€â”€ Qwen3-0.6B/              # Base model (1.5GB)
â”‚   â”œâ”€â”€ current_model/           # Active checkpoint (EMPTY - needs setup)
â”‚   â””â”€â”€ current_model_small/     # Small model checkpoint
â”‚
â”œâ”€â”€ backups/                     # Backups
â”‚   â””â”€â”€ consolidated/            # Consolidated backups
â”‚
â”œâ”€â”€ logs/                        # Training logs (daily rotation)
â”œâ”€â”€ status/                      # Status JSON files
â”œâ”€â”€ control/                     # Control files (.stop, .pause, etc.)
â”œâ”€â”€ inbox/                       # Drop zone for training files
â”œâ”€â”€ queue/                       # Priority queues
â”‚   â”œâ”€â”€ high/
â”‚   â”œâ”€â”€ normal/
â”‚   â”œâ”€â”€ low/
â”‚   â”œâ”€â”€ processing/              # Currently training
â”‚   â”œâ”€â”€ failed/                  # Failed files
â”‚   â””â”€â”€ recently_completed/
â”‚
â”œâ”€â”€ scratch/                     # Documentation & tests
â”‚   â”œâ”€â”€ REFACTOR_PLAN.md         # Original refactor plan
â”‚   â”œâ”€â”€ REFACTOR_COMPLETE.md     # Refactor completion summary
â”‚   â”œâ”€â”€ STEP1_COMPLETE.md        # Step 1 validation
â”‚   â”œâ”€â”€ STEP2_COMPLETE.md        # Step 2 validation
â”‚   â”œâ”€â”€ REFACTOR_PROGRESS.md     # Progress tracking
â”‚   â”œâ”€â”€ test_emoji_profile.py    # Emoji profile tests (6 tests)
â”‚   â””â”€â”€ test_regime3_profile.py  # Regime3 profile tests (7 tests)
â”‚
â””â”€â”€ archive/                     # Archived/experimental
    â”œâ”€â”€ configs/                 # Old configs
    â”œâ”€â”€ experiments/             # Experimental scripts
    â””â”€â”€ PERMANENT_ERROR_TRAINING/

# IGNORED (user data/notes):
GOTCHA_BUSINESS_MODEL/
OBSERVATIONS/
```

---

## ğŸ†• NEW: REFACTORED TRAINING MODULES

**Status:** Steps 1-5 Complete (2025-11-22)
**Git Tags:** 6 tags created (trainer_v1_emoji_baseline â†’ refactor_step5_regime3)

### **3-Layer Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”’ LAYER 1: CORE ENGINE (Proof-of-Concept API)            â”‚
â”‚  trainer/core/engine.py - TrainerEngine.run_job()         â”‚
â”‚  Clean API surface (demonstration)                         â”‚
â”‚  Production: Use core/train.py (backward compatible)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸšï¸  LAYER 2: CONFIG & TOGGLES (Production Ready)          â”‚
â”‚  trainer/config/schema.py - 8 dataclasses                  â”‚
â”‚  trainer/config/loader.py - ConfigLoader                   â”‚
â”‚  Single source of truth, type-safe, validated              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ§© LAYER 3: PROFILES / PLUGINS (Production Ready)         â”‚
â”‚  trainer/profiles/emoji_think.py - Emoji thinking/stop    â”‚
â”‚  trainer/profiles/regime3.py - Symbolic reasoning (NEW!)  â”‚
â”‚  trainer/monitoring/callbacks.py - LiveMonitorCallback    â”‚
â”‚  Pluggable, extensible, tested (13/13 tests passing)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Available Profiles**

**1. emoji_think (Original)**
- Emoji-based thinking patterns (random emoji, random count 2-8)
- Stop signals (random emoji, random count 2-4)
- Logit penalties for enforcement
- Full backward compatibility

**2. regime3 (NEW!)** â­
- Symbolic reasoning: `(op arg1 arg2)`
- Answer markers: `<<ANS_START>> ... <<ANS_END>>`
- Clean, penalty-free training
- Designed for structured logical reasoning

### **How to Use New Modules**

```python
# 1. Use Config System
from trainer.config import create_default_config
config = create_default_config(
    model_path="models/Qwen3-0.6B",
    dataset_path="data/train.jsonl",
    output_dir="outputs/run_001",
    base_model="Qwen/Qwen3-0.6B",
    model_architecture="Qwen3ForCausalLM",
    max_context_length=4096,
    vocab_size=151936
)

# 2. Use Profile System
from trainer.profiles import get_profile
profile = get_profile("emoji_think")  # or "regime3"
transformed = profile.transform_example(example, index, system_prompt)
processors = profile.build_logits_processors(tokenizer)

# 3. Use Monitoring
from trainer.monitoring import LiveMonitorCallback, TrainingStatusWriter
status_writer = TrainingStatusWriter("status/training_status.json")
callback = LiveMonitorCallback(...)

# 4. Use Engine API (Demo)
from trainer.core import TrainerEngine
engine = TrainerEngine(status_writer)
result = engine.run_job(config)
```

### **CLI Demo**

```bash
# Use new CLI wrapper
python3 -m trainer.cli_main --dataset data.jsonl --model qwen3 --output out --profile emoji_think
python3 -m trainer.cli_main --dataset data.jsonl --model qwen3 --output out --profile regime3

# Test profiles
python3 scratch/test_emoji_profile.py      # 6/6 tests âœ…
python3 scratch/test_regime3_profile.py    # 7/7 tests âœ…
```

### **Refactor Status**

- âœ… **Step 1:** Config extraction (tag: refactor_step1_config)
- âœ… **Step 2:** Profile extraction (tag: refactor_step2_profiles)
- âœ… **Step 3:** Monitoring extraction (tag: refactor_step3_monitoring)
- âœ… **Step 4:** TrainerEngine API (tag: refactor_step4_engine)
- âœ… **Step 5:** Regime3 profile (tag: refactor_step5_regime3)

**Result:** ~3,400 lines organized into 14 modules, fully tested, backward compatible

---

## ğŸ¯ CURRENT SYSTEM STATE

**Last Verified:** 2025-11-22 04:40 AM

### Model Status
- **Base model:** Qwen3-0.6B (exists at `/path/to/training/models/Qwen3-0.6B/`)
  - Size: 1.5GB
  - Type: Qwen3ForCausalLM
  - Hidden size: 1024, Layers: 28, Vocab: 151936
- **Current model:** EMPTY (needs initialization)
- **Training method:** Full model fine-tuning (no LoRA)
- **Last training attempt:** Failed with OOM at 04:02 AM

### Queue Status
- **Normal queue:** 0 files
- **Stuck files:** 3 files (287MB each, 100k examples)
  - 2 in `queue/failed/`
  - 1 in `queue/processing/`
- **Issue:** OOM crashes during training

### Service Status
- âœ… Disk manager: Running
- âŒ Training daemon: NOT running (PID dead)
- âŒ Monitors: NOT running
- âŒ Watchdogs: NOT running

### Configuration (`config.json`)
```json
{
  "model_name": "qwen2.5_0.5b",
  "model_path": "/path/to/training/models/Qwen3-0.6B",
  "batch_size": 19,
  "learning_rate": 0.0002,
  "eval_steps": 50,
  "save_steps": 1000,
  "max_length": 4096,
  "poll_interval": 30
}
```

### Disk Space
- **Available:** 731GB / 1.8TB (58% used)
- **Status:** Healthy

---

## âš¡ QUICK OPERATIONS

### Start All Services
```bash
cd /path/to/training
scripts/start_all.sh
```

This starts:
1. Auto disk manager
2. Training daemon
3. Live monitor (port 8080)
4. Memory stats API (port 8081)
5. Enhanced monitor (port 8082)

### Control Training
```bash
# Check status
python3 core/training_controller.py status

# Pause/resume/stop
python3 core/training_controller.py pause
python3 core/training_controller.py resume
python3 core/training_controller.py stop
```

### Queue Management
```bash
# Add file to queue
python3 core/training_queue.py add mydata.jsonl --priority high

# Check queue status
python3 core/training_queue.py status
python3 core/training_queue.py list
```

### Health Check
```bash
scripts/check_health.sh
python3 safety/comprehensive_health_check.py
python3 tools/analysis/state_tracker.py --check
```

### Monitor URLs
- Main UI: http://localhost:8080/live_monitor_ui_v2.html
- Memory Stats: http://localhost:8081/api/memory_stats
- Status JSON: http://localhost:8080/status/training_status.json

---

## ğŸ”§ COMMON ISSUES

### Training Daemon Not Running
```bash
# Check if running
ps aux | grep training_daemon | grep -v grep

# Restart if needed
cd /path/to/training
nohup python3 core/training_daemon.py --base-dir /path/to/training > training_output.log 2>&1 &
```

### OOM (Out of Memory) Crashes
**Symptoms:** Training crashes with CUDA OOM error

**Common causes:**
1. Batch size too high for available VRAM
2. Multiple daemon processes running (check with `ps aux`)
3. Eval step inference not clearing cache
4. Model too large for GPU

**Actions:**
```bash
# Check for multiple processes
ps aux | grep "python3.*training_daemon" | grep -v grep

# Kill all if multiple found
pkill -f training_daemon
sleep 3

# Reduce batch size
python3 tools/config/edit_config.py batch_size 16

# Restart daemon
nohup python3 core/training_daemon.py --base-dir /path/to/training > training_output.log 2>&1 &
```

### Stuck Files in Queue
**Check:**
```bash
ls -lh queue/processing/
ls -lh queue/failed/
```

**Clear:**
```bash
# Move back to normal queue (ask user first!)
mv queue/processing/* queue/normal/
mv queue/failed/* queue/normal/
```

---

## ğŸ“Š VALIDATION & METRICS

### Check Training Status
```bash
cat status/training_status.json | jq '{
  step: .current_step,
  train_loss: .loss,
  val_loss: .validation_loss,
  gap: .val_train_gap
}'
```

### Interpret Metrics
- **Train/Val Gap:**
  - < 0.3: Generalizing well
  - 0.3 - 0.5: Monitor closely
  - > 0.5: Possible overfitting

### Validate Data
```bash
python3 tools/data/validate_data.py --file my_data.jsonl
```

---

## ğŸ“ NOTES FOR CLAUDE

### System History
- System reorganized 2025-11-22 (99 Python files â†’ organized into 6 categories)
- All old documentation deleted (16 .md files removed)
- Fresh start - trust code as ground truth, not old docs

### Current Priorities
1. Fix stuck queue files (3 x 287MB files causing OOM)
2. Restart training daemon
3. Monitor system health

### When in Doubt
1. Run health check: `python3 safety/comprehensive_health_check.py`
2. Check system state: `python3 tools/analysis/state_tracker.py --check`
3. **ASK USER** before making changes
4. **ASK USER** before creating new documentation

---

## ğŸ”„ UPDATE LOG

**2025-11-22 (Late - Refactor Complete):**
- âœ… Completed full 5-step refactor (~3 hours)
- âœ… Created trainer/ module with 3-layer architecture
- âœ… Extracted config system (8 dataclasses, type-safe)
- âœ… Extracted emoji_think profile (emoji patterns + stop signals)
- âœ… Created regime3 profile (symbolic reasoning) â­ NEW
- âœ… Extracted monitoring system (callbacks + status writer)
- âœ… Created TrainerEngine API (proof-of-concept)
- âœ… 13/13 tests passing, 100% backward compatible
- âœ… All pushed to GitHub with 6 git tags
- **Production ready:** Can use new modules today or continue with core/train.py

**2025-11-22 (Morning - Reorganization):**
- Reorganized entire codebase (99 Python files â†’ 6 categories)
- Created 7 canonical documentation files
- Removed all old documentation (96+ files)
- Updated CLAUDE.md to reflect new structure
- **Architecture decision:** Pure training module - all inference on remote RTX 3090
- Added REMOTE_INFERENCE.md for remote server operations
- System state: Fresh start, daemon not running, 3 files stuck in queue
