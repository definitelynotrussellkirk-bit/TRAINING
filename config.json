{
  "model_name": "qwen3_0.6b",
  "model_display_name": "PURE BASE - Qwen3-0.6B (2025-11-22)",
  "model_path": "models/Qwen3-0.6B",
  "current_model_dir": "models/current_model",
  "batch_size": 1,
  "gradient_accumulation": 16,
  "learning_rate": 0.0004,
  "warmup_steps": 100,
  "epochs": 1,
  "load_in_4bit": false,
  "log_steps": 200,
  "eval_steps": 500,
  "num_eval_samples": 2,
  "save_steps": 1000,
  "poll_interval": 30,
  "snapshot_time": "03:00",
  "max_length": 2048,
  "base_model": "models/Qwen3-0.6B",
  "eval_max_tokens": 4096,
  "eval_timeout_seconds": 120,
  "self_correction": {
    "enabled": true,
    "auto_queue": true,
    "max_examples": 200,
    "generation_interval": null
  },
  "auto_run": {
    "enabled": true,
    "_comment": "When enabled, daemon auto-trains on queue items. When disabled, requires manual 'Run X Steps' button."
  },
  "auto_generate": {
    "enabled": true,
    "_comment": "Quest Master maintains at least min_queue_depth items on Quest Board",
    "count": 5000,
    "priority": "normal",
    "threshold": 0,
    "cooldown_sec": 180,
    "host": "localhost",
    "port": 8080,
    "min_queue_depth": 2
  },
  "remote_eval": {
    "enabled": true,
    "_comment": "Host/port/user/paths come from config/hosts.json. These are fallback defaults.",
    "host_id": "3090",
    "host": "192.168.x.x",
    "port": 8765,
    "remote_user": "user",
    "remote_models_dir": "~/llm/models",
    "eval_dataset": "data/validation/eval_dataset.jsonl",
    "eval_interval_steps": 5000,
    "sync_checkpoints": true,
    "metrics": [
      "accuracy",
      "loss"
    ]
  },
  "curriculum": {
    "enabled": true,
    "target_accuracy": 0.75,
    "current_skill": "syllo",
    "progression_mode": "automatic"
  },
  "retention": {
    "enabled": true,
    "_comment": "Uses RetentionManager with 36h age rule and 150GB limit"
  },
  "_comment_refactor": "New fields for refactored architecture (2025-11-22)",
  "profile": {
    "name": "none"
  },
  "hyperparams": {
    "fp_precision": "bf16",
    "max_length": 2048,
    "batch_size": 1,
    "gradient_accumulation": 16,
    "learning_rate": 0.0004,
    "use_gradient_checkpointing": true
  },
  "optimizer": {
    "type": "adamw",
    "_comment": "Options: 'adamw' (default) or 'muon' (orthogonalized momentum)",
    "adamw": {
      "lr": 0.0004,
      "betas": [
        0.9,
        0.999
      ],
      "eps": 1e-08,
      "weight_decay": 0.01
    },
    "muon": {
      "hidden_lr": 0.02,
      "aux_lr": 0.0003,
      "momentum": 0.95,
      "weight_decay": 0,
      "aux_betas": [
        0.9,
        0.95
      ],
      "aux_eps": 1e-10
    }
  },
  "performance_baselines": {
    "_comment": "POLICY 2: Expected performance metrics. Alert if degraded >50%.",
    "training_speed_it_per_sec": {
      "qwen3_0.6b": {
        "batch_size_1": 45.0,
        "batch_size_16": 12.0,
        "batch_size_30": 1200.0
      },
      "qwen3_4b": {
        "batch_size_1": 12.0,
        "batch_size_8": 3.5,
        "batch_size_16": 300.0
      }
    },
    "min_threshold_pct": 50,
    "alert_threshold_seconds": 60
  },
  "locked": {
    "base_model": "Qwen/Qwen3-0.6B",
    "model_architecture": "Qwen3ForCausalLM",
    "max_context_length": 4096,
    "vocab_size": 151936
  }
}